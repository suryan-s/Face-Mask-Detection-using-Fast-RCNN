{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryan-s/Face-Mask-Detection-using-Fast-RCNN/blob/main/ObjectDetectionTransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Project/images /content/Tensorflow/workspace"
      ],
      "metadata": {
        "id": "OVKLxcU-ggIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"suryanleo\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"a8a0350c0ed88e63fa51d3f303d8fdfd\" # key from the json file\n",
        "\n",
        "!kaggle datasets download -d andrewmvd/face-mask-detection"
      ],
      "metadata": {
        "id": "bEkEtec8p1N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'faster_rcnn_resnet101_v1' \n",
        "PRETRAINED_MODEL_NAME = 'faster_rcnn_resnet101_v1_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848b4351-6a3b-4dfd-c7fe-05e366fe42d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=5987c57cf010ef3e95f8398a3fe6e4b560e4379f061d39ac5f6cc8d45689dfde\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install wget\n",
        "import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49845334-c0a1-4357-c6a0-7fc6cdbee712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 76342, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "Resolving deltas: 100% (54168/54168), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb072ef-ea45-4b4f-eda2-ef028b746f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.40.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 58.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.1 kB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 70.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 66.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Collecting keras\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.47.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 71.7 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.22.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 71.6 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.7.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 73.7 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 26.4 MB/s \n",
            "\u001b[?25hCollecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.9.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694955 sha256=d2605929d9461475c37ed313de2b7bea4ebdf398663abbea9849b89f6373eccd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vw9lh50b/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=5493cfcb381950ec6352a776f052e6fd4908c940d7751b3239cdd292036305fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=315112b26d1cc584e161709b9c6a62b4086983c9d272af357bf293ab4d36dfef\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=e7dd14caebc258469e9d022dc59670ebc1e71977a6931f9e8f27c659002c9b0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=42b64d87fcb72b9668bdd3bece15fec6c287903f21ee7f07e263afcd311e131b\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=b34082d96b9f845851c64049c390138d5864c9c9f6ea3637dd1355457431ff2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow, portalocker, docopt, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.2.0\n",
            "    Uninstalling pymongo-4.2.0:\n",
            "      Successfully uninstalled pymongo-4.2.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed apache-beam-2.40.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.5 dill-0.3.1.1 docopt-0.6.2 fastavro-1.6.0 flatbuffers-1.12 gast-0.4.0 hdfs-2.7.0 keras-2.9.0 lvis-0.5.3 object-detection-0.1 orjson-3.7.12 portalocker-2.5.1 proto-plus-1.22.0 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-estimator-2.9.0 tensorflow-io-0.26.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.9.0 tf-models-official-2.9.2 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "id": "pKvUFDXvp0Rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb3f15b-7689-414d-f57b-b2654cab7b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- ----------------------\n",
            "absl-py                       1.2.0\n",
            "aiohttp                       3.8.1\n",
            "aiosignal                     1.2.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.0\n",
            "apache-beam                   2.40.0\n",
            "appdirs                       1.4.4\n",
            "arviz                         0.12.1\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "async-timeout                 4.0.2\n",
            "asynctest                     0.13.0\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.1.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.4\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.10.3\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.1\n",
            "blis                          0.7.8\n",
            "bokeh                         2.3.3\n",
            "branca                        0.5.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.6.15\n",
            "cffi                          1.15.1\n",
            "cftime                        1.6.1\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.1.0\n",
            "click                         7.1.2\n",
            "clikit                        0.6.2\n",
            "cloudpickle                   2.1.0\n",
            "cmake                         3.22.6\n",
            "cmdstanpy                     1.0.4\n",
            "colorama                      0.4.5\n",
            "colorcet                      3.0.0\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "crashtest                     0.3.1\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda111                  9.4.0\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.2.1\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.6\n",
            "Cython                        0.29.32\n",
            "daft                          0.0.4\n",
            "dask                          2022.2.0\n",
            "datascience                   0.17.5\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "deprecat                      2.1.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   2022.2.0\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.7\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.319\n",
            "easydict                      1.9\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.4.0\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         0.7.1\n",
            "fa2                           0.3.5\n",
            "fastai                        2.7.9\n",
            "fastavro                      1.6.0\n",
            "fastcore                      1.5.18\n",
            "fastdownload                  0.0.7\n",
            "fastdtw                       0.3.4\n",
            "fastjsonschema                2.16.1\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8\n",
            "feather-format                0.4.1\n",
            "filelock                      3.8.0\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   1.12\n",
            "folium                        0.12.1.post1\n",
            "frozenlist                    1.3.1\n",
            "fsspec                        2022.7.1\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.31.6\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.2\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.56.4\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.2\n",
            "grpcio                        1.47.0\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.1\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.14.2\n",
            "holoviews                     1.14.9\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "httpstan                      4.6.1\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "idna                          2.10\n",
            "imageio                       2.9.0\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "importlib-metadata            4.12.0\n",
            "importlib-resources           5.9.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "intel-openmp                  2022.1.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    8.0.1\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.14\n",
            "jaxlib                        0.3.14+cuda11.cudnn805\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.1.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter-core                  4.11.1\n",
            "jupyterlab-widgets            3.0.1\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.9.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.2.1\n",
            "langcodes                     3.3.0\n",
            "libclang                      14.0.6\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.39.0\n",
            "lmdb                          0.99\n",
            "locket                        1.0.0\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.9.1\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.0.1\n",
            "marshmallow                   3.17.0\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-venn               0.11.7\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.7.3\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.14.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.4\n",
            "multidict                     6.0.2\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.8\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.4.0\n",
            "netCDF4                       1.6.0\n",
            "networkx                      2.6.3\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.7\n",
            "notebook                      5.3.1\n",
            "numba                         0.56.0\n",
            "numexpr                       2.8.3\n",
            "numpy                         1.21.6\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.0\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.6.0.66\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.6.0.66\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.7.12\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.2\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pastel                        0.2.1\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.6.2\n",
            "patsy                         0.5.2\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.8.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.5.1\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.7\n",
            "prettytable                   3.3.0\n",
            "progressbar2                  3.38.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1\n",
            "proto-plus                    1.22.0\n",
            "protobuf                      3.19.4\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.9.3\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       6.0.1\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.4\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydantic                      1.9.2\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pylev                         1.4.0\n",
            "pymc3                         3.11.5\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.18.1\n",
            "pysimdjson                    3.2.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        3.3.0\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                6.1.2\n",
            "python-utils                  3.3.3\n",
            "pytz                          2022.2.1\n",
            "pyviz-comms                   2.2.0\n",
            "PyWavelets                    1.3.0\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post2\n",
            "qudida                        0.0.4\n",
            "regex                         2022.6.2\n",
            "requests                      2.28.1\n",
            "requests-oauthlib             1.3.1\n",
            "resampy                       0.4.0\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.9\n",
            "sacrebleu                     2.2.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.7.3\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.0\n",
            "seaborn                       0.11.2\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.97\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.4\n",
            "six                           1.15.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         3.4.1\n",
            "spacy-legacy                  3.0.10\n",
            "spacy-loggers                 1.0.3\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.40\n",
            "sqlparse                      0.4.2\n",
            "srsly                         2.4.4\n",
            "statsmodels                   0.12.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.0.1\n",
            "tensorboard                   2.9.1\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.9.1\n",
            "tensorflow-addons             0.17.1\n",
            "tensorflow-datasets           4.6.0\n",
            "tensorflow-estimator          2.9.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.26.0\n",
            "tensorflow-io-gcs-filesystem  0.26.0\n",
            "tensorflow-metadata           1.9.0\n",
            "tensorflow-model-optimization 0.7.3\n",
            "tensorflow-probability        0.16.0\n",
            "tensorflow-text               2.9.0\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.9.2\n",
            "tf-slim                       1.1.0\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         8.1.0\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2021.11.2\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.12.1+cu113\n",
            "torchaudio                    0.12.1+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.13.1\n",
            "torchvision                   0.13.1+cu113\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.64.0\n",
            "traitlets                     5.1.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typer                         0.4.2\n",
            "typing-extensions             4.1.1\n",
            "tzlocal                       1.5.1\n",
            "ujson                         5.4.0\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.10.1\n",
            "wcwidth                       0.2.5\n",
            "webargs                       8.2.0\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wget                          3.2\n",
            "wheel                         0.37.1\n",
            "widgetsnbextension            4.0.1\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.14.1\n",
            "xarray                        0.20.2\n",
            "xarray-einstats               0.2.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yarl                          1.8.1\n",
            "yellowbrick                   1.4\n",
            "zict                          2.2.0\n",
            "zipp                          3.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "id": "RKLSfOW-p0Rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28b2749-f301-4bc9-c02d-68c324a16bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-08-20 05:35:46.391732: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0820 05:35:46.727944 139907386402688 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.55s\n",
            "I0820 05:35:46.981563 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.55s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "I0820 05:35:47.484988 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "I0820 05:35:47.735065 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
            "I0820 05:35:48.164744 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.69s\n",
            "I0820 05:35:49.850897 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.69s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0820 05:35:49.851817 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0820 05:35:49.875025 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0820 05:35:49.890311 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0820 05:35:49.904090 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "I0820 05:35:49.999942 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0820 05:35:50.090952 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0820 05:35:50.181754 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0820 05:35:50.275006 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0820 05:35:50.365810 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0820 05:35:50.392700 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0820 05:35:50.558346 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0820 05:35:50.558498 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0820 05:35:50.558564 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0820 05:35:50.560554 139907386402688 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0820 05:35:50.576649 139907386402688 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0820 05:35:50.576770 139907386402688 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0820 05:35:50.633303 139907386402688 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0820 05:35:50.633444 139907386402688 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0820 05:35:50.783769 139907386402688 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0820 05:35:50.783931 139907386402688 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0820 05:35:50.940547 139907386402688 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0820 05:35:50.940721 139907386402688 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0820 05:35:51.311875 139907386402688 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0820 05:35:51.312041 139907386402688 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0820 05:35:51.537823 139907386402688 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0820 05:35:51.538013 139907386402688 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0820 05:35:51.830430 139907386402688 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0820 05:35:51.830601 139907386402688 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0820 05:35:51.910917 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0820 05:35:51.940901 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0820 05:35:51.989409 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0820 05:35:51.989571 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0820 05:35:51.989657 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0820 05:35:51.991197 139907386402688 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0820 05:35:52.006180 139907386402688 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0820 05:35:52.006288 139907386402688 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0820 05:35:52.130526 139907386402688 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0820 05:35:52.130713 139907386402688 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0820 05:35:52.365418 139907386402688 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0820 05:35:52.365619 139907386402688 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0820 05:35:52.591327 139907386402688 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0820 05:35:52.591497 139907386402688 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0820 05:35:52.895751 139907386402688 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0820 05:35:52.895916 139907386402688 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0820 05:35:53.247305 139907386402688 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0820 05:35:53.253183 139907386402688 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0820 05:35:53.842863 139907386402688 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0820 05:35:53.843080 139907386402688 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0820 05:35:54.088191 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0820 05:35:54.133187 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0820 05:35:54.237340 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0820 05:35:54.237536 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0820 05:35:54.237614 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0820 05:35:54.239952 139907386402688 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0820 05:35:54.261740 139907386402688 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0820 05:35:54.261918 139907386402688 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0820 05:35:54.445990 139907386402688 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0820 05:35:54.446235 139907386402688 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0820 05:35:54.845202 139907386402688 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0820 05:35:54.845404 139907386402688 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0820 05:35:55.274607 139907386402688 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0820 05:35:55.274845 139907386402688 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0820 05:35:55.933145 139907386402688 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0820 05:35:55.933358 139907386402688 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0820 05:35:56.462922 139907386402688 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0820 05:35:56.463145 139907386402688 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0820 05:35:57.173463 139907386402688 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0820 05:35:57.173696 139907386402688 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0820 05:35:57.422002 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0820 05:35:57.473742 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0820 05:35:57.587209 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0820 05:35:57.587399 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0820 05:35:57.587474 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0820 05:35:57.590244 139907386402688 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0820 05:35:57.616000 139907386402688 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0820 05:35:57.616169 139907386402688 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0820 05:35:58.279306 139907386402688 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0820 05:35:58.279505 139907386402688 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0820 05:35:58.646005 139907386402688 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0820 05:35:58.646242 139907386402688 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0820 05:35:59.047491 139907386402688 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0820 05:35:59.047706 139907386402688 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0820 05:35:59.775642 139907386402688 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0820 05:35:59.775862 139907386402688 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0820 05:36:00.584148 139907386402688 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0820 05:36:00.584356 139907386402688 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0820 05:36:01.365739 139907386402688 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0820 05:36:01.365956 139907386402688 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0820 05:36:01.595742 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0820 05:36:01.639609 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0820 05:36:01.766901 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0820 05:36:01.767122 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0820 05:36:01.767219 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0820 05:36:01.769716 139907386402688 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0820 05:36:01.800695 139907386402688 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0820 05:36:01.800827 139907386402688 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0820 05:36:02.019570 139907386402688 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0820 05:36:02.019763 139907386402688 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0820 05:36:02.679062 139907386402688 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0820 05:36:02.679320 139907386402688 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0820 05:36:03.395544 139907386402688 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0820 05:36:03.395749 139907386402688 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0820 05:36:04.280335 139907386402688 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0820 05:36:04.280544 139907386402688 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0820 05:36:05.041662 139907386402688 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0820 05:36:05.052172 139907386402688 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0820 05:36:06.176258 139907386402688 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0820 05:36:06.176472 139907386402688 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0820 05:36:06.555433 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0820 05:36:06.607933 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0820 05:36:06.809030 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0820 05:36:06.809264 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0820 05:36:06.809356 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0820 05:36:06.816509 139907386402688 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0820 05:36:06.851688 139907386402688 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0820 05:36:06.851857 139907386402688 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0820 05:36:07.218458 139907386402688 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0820 05:36:07.218615 139907386402688 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0820 05:36:07.600740 139907386402688 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0820 05:36:07.600900 139907386402688 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0820 05:36:08.177595 139907386402688 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0820 05:36:08.177772 139907386402688 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0820 05:36:08.708046 139907386402688 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0820 05:36:08.708229 139907386402688 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0820 05:36:09.238512 139907386402688 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0820 05:36:09.238722 139907386402688 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0820 05:36:09.919655 139907386402688 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0820 05:36:09.919841 139907386402688 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0820 05:36:10.141752 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0820 05:36:10.172568 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0820 05:36:10.261225 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0820 05:36:10.261376 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0820 05:36:10.261440 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0820 05:36:10.262954 139907386402688 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0820 05:36:10.278233 139907386402688 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0820 05:36:10.278355 139907386402688 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0820 05:36:10.457327 139907386402688 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0820 05:36:10.457515 139907386402688 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0820 05:36:10.894181 139907386402688 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0820 05:36:10.894349 139907386402688 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0820 05:36:11.347543 139907386402688 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0820 05:36:11.347708 139907386402688 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0820 05:36:11.947210 139907386402688 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0820 05:36:11.947404 139907386402688 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0820 05:36:12.548434 139907386402688 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0820 05:36:12.548604 139907386402688 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0820 05:36:13.383028 139907386402688 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0820 05:36:13.383207 139907386402688 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0820 05:36:13.806664 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0820 05:36:13.834246 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0820 05:36:13.925394 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0820 05:36:13.925551 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0820 05:36:13.925624 139907386402688 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0820 05:36:13.927112 139907386402688 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0820 05:36:13.942240 139907386402688 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0820 05:36:13.942346 139907386402688 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0820 05:36:14.182773 139907386402688 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0820 05:36:14.182932 139907386402688 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0820 05:36:14.713227 139907386402688 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0820 05:36:14.713391 139907386402688 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0820 05:36:15.238674 139907386402688 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0820 05:36:15.238853 139907386402688 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0820 05:36:15.988234 139907386402688 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0820 05:36:15.988397 139907386402688 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0820 05:36:16.740646 139907386402688 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0820 05:36:16.740837 139907386402688 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0820 05:36:17.715772 139907386402688 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0820 05:36:17.715938 139907386402688 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0820 05:36:18.019003 139907386402688 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0820 05:36:18.046354 139907386402688 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.76s\n",
            "I0820 05:36:18.157804 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.76s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0820 05:36:18.163140 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0820 05:36:18.164702 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0820 05:36:18.165184 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0820 05:36:18.166544 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0820 05:36:18.167805 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0820 05:36:18.168241 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0820 05:36:18.169195 139907386402688 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 32.740s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x3DIJ-rXp0Ri"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "csofht2npfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b1a5f0-ce9b-4ec0-e38d-426f25686a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-20 05:36:19--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.253.118.128, 2404:6800:4003:c05::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.253.118.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 353643040 (337M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet1 100%[===================>] 337.26M  52.0MB/s    in 6.9s    \n",
            "\n",
            "2022-08-20 05:36:27 (48.7 MB/s) - ‘faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz’ saved [353643040/353643040]\n",
            "\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint/\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/pipeline.config\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/saved_model/\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/saved_model/variables/\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'with_mask', 'id':1}, {'name':'without_mask', 'id':2}, {'name':'mask_weared_incorrect', 'id':3}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvf5WccwrFGq"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LHZtIWuHp0Rj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "447f4341-6feb-4509-ac24-7401d5ded0ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'generate_tfrecord.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "wget.download('https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPFToGZqpfDD"
      },
      "outputs": [],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQA13-afpfDF"
      },
      "outputs": [],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oCJG49pp0Rk"
      },
      "outputs": [],
      "source": [
        "print(os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.faster_rcnn.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 32\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=20000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4OXXi-ApfDH"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "id": "R8SuPwvUofiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "id": "mFHcf25HN8H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYsgEPx9pfDH"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqTV2jGBpfDH"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS2umPyCp0Rm"
      },
      "outputs": [],
      "source": [
        "# Prevent GPU complete consumption\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try: \n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "    except RunTimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-11')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpzn1SMry1yK"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'testimg2.jpg')\n",
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErSx-ONop0Rn"
      },
      "outputs": [],
      "source": [
        "detections.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNAaYAo0WVL"
      },
      "source": [
        "# 10. Real Time Detections from your Webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_grs6OGpfDJ"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CcT_bnUp0Rn"
      },
      "source": [
        "# Sample test run live"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frNx-hCdp0Rn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from google.protobuf import text_format\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
        "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
        "APIMODEL_PATH = 'Tensorflow/models'\n",
        "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
        "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
        "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
        "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
        "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
        "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'\n",
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'\n",
        "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "try:\n",
        "    # Restore checkpoint\n",
        "    ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "    ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-11')).expect_partial()\n",
        "except tf.errors.NotFoundError:\n",
        "    print(\"No checkpoint found\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections\n",
        "\n",
        "# Setup capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "while True: \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=2,\n",
        "                min_score_thresh=.7,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Lsp3tCpfDJ"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sw1ULgHpfDJ"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ6UzY_fpfDK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "outputs": [],
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB2AGNmJpfDK"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7rfT4-hpfDK"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "outputs": [],
      "source": [
        "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUw73FHpfDK"
      },
      "source": [
        "# 12. Conversion to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "outputs": [],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1r5YO3rpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-xWpHN8pfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "outputs": [],
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DGgkFBdp0Rp"
      },
      "outputs": [],
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8GwUeoFpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbd7gqHMpfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "whShhB0x3PYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be04ed92-a8ad-4c7a-a010-aaa9afa8e741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip face-mask-detection.zip"
      ],
      "metadata": {
        "id": "rNwiQNuPr4hW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ObjectDetectionTransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4_YRZu7npfDH",
        "orvRk02UpfDI",
        "0EmsmbBZpfDI",
        "IsNAaYAo0WVL",
        "5CcT_bnUp0Rn",
        "rzlM4jt0pfDJ",
        "wTPmdqaXpfDK",
        "VtUw73FHpfDK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "66e94f7b7489250cb157aed0c9bbcac446a8abe6882d1b25d8e0e210eea02991"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}